{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The task at hand is classification of wine quality\n",
    "\n",
    "We will use 3 different approaches:\n",
    "\n",
    "- A standard neural network (feed fordward nn)\n",
    "- A bayesian neural network that will take into account epistemic (model) uncertainty on the predicted labels\n",
    "- A probabilistic neural network that will take into account both aleatoric (data) and epistemic (model) uncertainty on the predicted labels\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. [Data Inspection](#inspection) \n",
    "    - Loading\n",
    "    - Inspection\n",
    "    - Preprocessing\n",
    "2. [Modeling](#model-definition)\n",
    "    - Standard Neural Network\n",
    "    - Bayesian Neural Network\n",
    "    - Probabilistic Neural Network\n",
    "3. [Prediction](#prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/codespace/.local/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (2.12.0)\n",
      "Requirement already satisfied: tensorflow_datasets in /home/codespace/.local/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (4.9.2)\n",
      "Collecting tensorflow_probability (from -r ../requirements.txt (line 3))\n",
      "  Downloading tensorflow_probability-0.20.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.10/site-packages (from -r ../requirements.txt (line 4)) (3.7.1)\n",
      "Requirement already satisfied: seaborn in /home/codespace/.local/lib/python3.10/site-packages (from -r ../requirements.txt (line 5)) (0.12.2)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.10/site-packages (from -r ../requirements.txt (line 6)) (1.2.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (23.5.9)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (1.55.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (0.4.10)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (4.23.1)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (4.6.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow->-r ../requirements.txt (line 1)) (0.32.0)\n",
      "Requirement already satisfied: array-record in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets->-r ../requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: click in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets->-r ../requirements.txt (line 2)) (8.1.3)\n",
      "Requirement already satisfied: dm-tree in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets->-r ../requirements.txt (line 2)) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets->-r ../requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: promise in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets->-r ../requirements.txt (line 2)) (2.3)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets->-r ../requirements.txt (line 2)) (5.9.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets->-r ../requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets->-r ../requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: toml in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets->-r ../requirements.txt (line 2)) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets->-r ../requirements.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_probability->-r ../requirements.txt (line 3)) (5.1.1)\n",
      "Collecting cloudpickle>=1.3 (from tensorflow_probability->-r ../requirements.txt (line 3))\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 4)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 4)) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 4)) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 4)) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/codespace/.local/lib/python3.10/site-packages (from seaborn->-r ../requirements.txt (line 5)) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->-r ../requirements.txt (line 6)) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->-r ../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->-r ../requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow->-r ../requirements.txt (line 1)) (0.40.0)\n",
      "Requirement already satisfied: importlib_resources in /home/codespace/.local/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets->-r ../requirements.txt (line 2)) (5.12.0)\n",
      "Requirement already satisfied: zipp in /home/codespace/.local/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets->-r ../requirements.txt (line 2)) (3.15.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->-r ../requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=0.25->seaborn->-r ../requirements.txt (line 5)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=0.25->seaborn->-r ../requirements.txt (line 5)) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets->-r ../requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets->-r ../requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets->-r ../requirements.txt (line 2)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets->-r ../requirements.txt (line 2)) (2023.5.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (2.18.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (2.3.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow_datasets->-r ../requirements.txt (line 2)) (1.59.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/codespace/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/codespace/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/codespace/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/codespace/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->-r ../requirements.txt (line 1)) (3.2.2)\n",
      "Installing collected packages: cloudpickle, tensorflow_probability\n",
      "Successfully installed cloudpickle-2.2.1 tensorflow_probability-0.20.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Software install (as required)\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection <a name=\"inspection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading : load the wine dataset\n",
    "# load train, test & validation splits into 70%, 30% respectively\n",
    "(ds_train, ds_test), ds_info   = tfds.load(\n",
    "    \"wine_quality\", \n",
    "    split=[\"train[:70%]\",\"train[70%:]\"],\n",
    "    as_supervised=True,\n",
    "    with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturesDict({\n",
       "    'features': FeaturesDict({\n",
       "        'alcohol': float32,\n",
       "        'chlorides': float32,\n",
       "        'citric acid': float32,\n",
       "        'density': float32,\n",
       "        'fixed acidity': float32,\n",
       "        'free sulfur dioxide': float32,\n",
       "        'pH': float32,\n",
       "        'residual sugar': float32,\n",
       "        'sulphates': float64,\n",
       "        'total sulfur dioxide': float32,\n",
       "        'volatile acidity': float32,\n",
       "    }),\n",
       "    'quality': int32,\n",
       "})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 4898\n",
      "Train set size: 3429\n",
      "Test set size : 1469\n",
      "Feature names : ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic Info\n",
    "feature_names=list(ds_info.features['features'].keys())\n",
    "print(\"Total examples: %d\" %(len(ds_train)+len(ds_test)))\n",
    "print(\"Train set size: %d\" %len(ds_train)) \n",
    "print(\"Test set size : %d\" %len(ds_test))   \n",
    "print(\"Feature names : %s\" %feature_names)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 22:17:48.638538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-23 22:17:48.639151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-23 22:17:48.711533: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_965b0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_965b0_level0_col0\" class=\"col_heading level0 col0\" >features/alcohol</th>\n",
       "      <th id=\"T_965b0_level0_col1\" class=\"col_heading level0 col1\" >features/chlorides</th>\n",
       "      <th id=\"T_965b0_level0_col2\" class=\"col_heading level0 col2\" >features/citric acid</th>\n",
       "      <th id=\"T_965b0_level0_col3\" class=\"col_heading level0 col3\" >features/density</th>\n",
       "      <th id=\"T_965b0_level0_col4\" class=\"col_heading level0 col4\" >features/fixed acidity</th>\n",
       "      <th id=\"T_965b0_level0_col5\" class=\"col_heading level0 col5\" >features/free sulfur dioxide</th>\n",
       "      <th id=\"T_965b0_level0_col6\" class=\"col_heading level0 col6\" >features/pH</th>\n",
       "      <th id=\"T_965b0_level0_col7\" class=\"col_heading level0 col7\" >features/residual sugar</th>\n",
       "      <th id=\"T_965b0_level0_col8\" class=\"col_heading level0 col8\" >features/sulphates</th>\n",
       "      <th id=\"T_965b0_level0_col9\" class=\"col_heading level0 col9\" >features/total sulfur dioxide</th>\n",
       "      <th id=\"T_965b0_level0_col10\" class=\"col_heading level0 col10\" >features/volatile acidity</th>\n",
       "      <th id=\"T_965b0_level0_col11\" class=\"col_heading level0 col11\" >quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_965b0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_965b0_row0_col0\" class=\"data row0 col0\" >9.0</td>\n",
       "      <td id=\"T_965b0_row0_col1\" class=\"data row0 col1\" >0.05400000140070915</td>\n",
       "      <td id=\"T_965b0_row0_col2\" class=\"data row0 col2\" >0.3400000035762787</td>\n",
       "      <td id=\"T_965b0_row0_col3\" class=\"data row0 col3\" >1.0008000135421753</td>\n",
       "      <td id=\"T_965b0_row0_col4\" class=\"data row0 col4\" >7.599999904632568</td>\n",
       "      <td id=\"T_965b0_row0_col5\" class=\"data row0 col5\" >44.0</td>\n",
       "      <td id=\"T_965b0_row0_col6\" class=\"data row0 col6\" >3.2200000286102295</td>\n",
       "      <td id=\"T_965b0_row0_col7\" class=\"data row0 col7\" >18.350000381469727</td>\n",
       "      <td id=\"T_965b0_row0_col8\" class=\"data row0 col8\" >0.550000011920929</td>\n",
       "      <td id=\"T_965b0_row0_col9\" class=\"data row0 col9\" >197.0</td>\n",
       "      <td id=\"T_965b0_row0_col10\" class=\"data row0 col10\" >0.3199999928474426</td>\n",
       "      <td id=\"T_965b0_row0_col11\" class=\"data row0 col11\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_965b0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_965b0_row1_col0\" class=\"data row1 col0\" >12.199999809265137</td>\n",
       "      <td id=\"T_965b0_row1_col1\" class=\"data row1 col1\" >0.06300000101327896</td>\n",
       "      <td id=\"T_965b0_row1_col2\" class=\"data row1 col2\" >0.49000000953674316</td>\n",
       "      <td id=\"T_965b0_row1_col3\" class=\"data row1 col3\" >0.991100013256073</td>\n",
       "      <td id=\"T_965b0_row1_col4\" class=\"data row1 col4\" >6.300000190734863</td>\n",
       "      <td id=\"T_965b0_row1_col5\" class=\"data row1 col5\" >35.0</td>\n",
       "      <td id=\"T_965b0_row1_col6\" class=\"data row1 col6\" >3.380000114440918</td>\n",
       "      <td id=\"T_965b0_row1_col7\" class=\"data row1 col7\" >1.2000000476837158</td>\n",
       "      <td id=\"T_965b0_row1_col8\" class=\"data row1 col8\" >0.41999998688697815</td>\n",
       "      <td id=\"T_965b0_row1_col9\" class=\"data row1 col9\" >92.0</td>\n",
       "      <td id=\"T_965b0_row1_col10\" class=\"data row1 col10\" >0.27000001072883606</td>\n",
       "      <td id=\"T_965b0_row1_col11\" class=\"data row1 col11\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_965b0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_965b0_row2_col0\" class=\"data row2 col0\" >11.199999809265137</td>\n",
       "      <td id=\"T_965b0_row2_col1\" class=\"data row2 col1\" >0.028999999165534973</td>\n",
       "      <td id=\"T_965b0_row2_col2\" class=\"data row2 col2\" >0.10999999940395355</td>\n",
       "      <td id=\"T_965b0_row2_col3\" class=\"data row2 col3\" >0.9907600283622742</td>\n",
       "      <td id=\"T_965b0_row2_col4\" class=\"data row2 col4\" >5.300000190734863</td>\n",
       "      <td id=\"T_965b0_row2_col5\" class=\"data row2 col5\" >6.0</td>\n",
       "      <td id=\"T_965b0_row2_col6\" class=\"data row2 col6\" >3.509999990463257</td>\n",
       "      <td id=\"T_965b0_row2_col7\" class=\"data row2 col7\" >1.100000023841858</td>\n",
       "      <td id=\"T_965b0_row2_col8\" class=\"data row2 col8\" >0.47999998927116394</td>\n",
       "      <td id=\"T_965b0_row2_col9\" class=\"data row2 col9\" >51.0</td>\n",
       "      <td id=\"T_965b0_row2_col10\" class=\"data row2 col10\" >0.4300000071525574</td>\n",
       "      <td id=\"T_965b0_row2_col11\" class=\"data row2 col11\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_965b0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_965b0_row3_col0\" class=\"data row3 col0\" >9.0</td>\n",
       "      <td id=\"T_965b0_row3_col1\" class=\"data row3 col1\" >0.10999999940395355</td>\n",
       "      <td id=\"T_965b0_row3_col2\" class=\"data row3 col2\" >0.27000001072883606</td>\n",
       "      <td id=\"T_965b0_row3_col3\" class=\"data row3 col3\" >0.996720016002655</td>\n",
       "      <td id=\"T_965b0_row3_col4\" class=\"data row3 col4\" >6.599999904632568</td>\n",
       "      <td id=\"T_965b0_row3_col5\" class=\"data row3 col5\" >20.0</td>\n",
       "      <td id=\"T_965b0_row3_col6\" class=\"data row3 col6\" >3.0799999237060547</td>\n",
       "      <td id=\"T_965b0_row3_col7\" class=\"data row3 col7\" >10.699999809265137</td>\n",
       "      <td id=\"T_965b0_row3_col8\" class=\"data row3 col8\" >0.4099999964237213</td>\n",
       "      <td id=\"T_965b0_row3_col9\" class=\"data row3 col9\" >103.0</td>\n",
       "      <td id=\"T_965b0_row3_col10\" class=\"data row3 col10\" >0.4099999964237213</td>\n",
       "      <td id=\"T_965b0_row3_col11\" class=\"data row3 col11\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_965b0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_965b0_row4_col0\" class=\"data row4 col0\" >12.0</td>\n",
       "      <td id=\"T_965b0_row4_col1\" class=\"data row4 col1\" >0.03500000014901161</td>\n",
       "      <td id=\"T_965b0_row4_col2\" class=\"data row4 col2\" >0.30000001192092896</td>\n",
       "      <td id=\"T_965b0_row4_col3\" class=\"data row4 col3\" >0.9901599884033203</td>\n",
       "      <td id=\"T_965b0_row4_col4\" class=\"data row4 col4\" >5.900000095367432</td>\n",
       "      <td id=\"T_965b0_row4_col5\" class=\"data row4 col5\" >57.0</td>\n",
       "      <td id=\"T_965b0_row4_col6\" class=\"data row4 col6\" >3.0899999141693115</td>\n",
       "      <td id=\"T_965b0_row4_col7\" class=\"data row4 col7\" >3.799999952316284</td>\n",
       "      <td id=\"T_965b0_row4_col8\" class=\"data row4 col8\" >0.3400000035762787</td>\n",
       "      <td id=\"T_965b0_row4_col9\" class=\"data row4 col9\" >135.0</td>\n",
       "      <td id=\"T_965b0_row4_col10\" class=\"data row4 col10\" >0.3400000035762787</td>\n",
       "      <td id=\"T_965b0_row4_col11\" class=\"data row4 col11\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_965b0_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_965b0_row5_col0\" class=\"data row5 col0\" >10.300000190734863</td>\n",
       "      <td id=\"T_965b0_row5_col1\" class=\"data row5 col1\" >0.054999999701976776</td>\n",
       "      <td id=\"T_965b0_row5_col2\" class=\"data row5 col2\" >0.38999998569488525</td>\n",
       "      <td id=\"T_965b0_row5_col3\" class=\"data row5 col3\" >0.9965199828147888</td>\n",
       "      <td id=\"T_965b0_row5_col4\" class=\"data row5 col4\" >7.0</td>\n",
       "      <td id=\"T_965b0_row5_col5\" class=\"data row5 col5\" >42.0</td>\n",
       "      <td id=\"T_965b0_row5_col6\" class=\"data row5 col6\" >3.369999885559082</td>\n",
       "      <td id=\"T_965b0_row5_col7\" class=\"data row5 col7\" >7.5</td>\n",
       "      <td id=\"T_965b0_row5_col8\" class=\"data row5 col8\" >0.5400000214576721</td>\n",
       "      <td id=\"T_965b0_row5_col9\" class=\"data row5 col9\" >218.0</td>\n",
       "      <td id=\"T_965b0_row5_col10\" class=\"data row5 col10\" >0.3100000023841858</td>\n",
       "      <td id=\"T_965b0_row5_col11\" class=\"data row5 col11\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_965b0_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_965b0_row6_col0\" class=\"data row6 col0\" >10.699999809265137</td>\n",
       "      <td id=\"T_965b0_row6_col1\" class=\"data row6 col1\" >0.05400000140070915</td>\n",
       "      <td id=\"T_965b0_row6_col2\" class=\"data row6 col2\" >0.3499999940395355</td>\n",
       "      <td id=\"T_965b0_row6_col3\" class=\"data row6 col3\" >0.9917799830436707</td>\n",
       "      <td id=\"T_965b0_row6_col4\" class=\"data row6 col4\" >7.300000190734863</td>\n",
       "      <td id=\"T_965b0_row6_col5\" class=\"data row6 col5\" >31.0</td>\n",
       "      <td id=\"T_965b0_row6_col6\" class=\"data row6 col6\" >3.180000066757202</td>\n",
       "      <td id=\"T_965b0_row6_col7\" class=\"data row6 col7\" >1.600000023841858</td>\n",
       "      <td id=\"T_965b0_row6_col8\" class=\"data row6 col8\" >0.4699999988079071</td>\n",
       "      <td id=\"T_965b0_row6_col9\" class=\"data row6 col9\" >148.0</td>\n",
       "      <td id=\"T_965b0_row6_col10\" class=\"data row6 col10\" >0.2800000011920929</td>\n",
       "      <td id=\"T_965b0_row6_col11\" class=\"data row6 col11\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_965b0_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_965b0_row7_col0\" class=\"data row7 col0\" >10.399999618530273</td>\n",
       "      <td id=\"T_965b0_row7_col1\" class=\"data row7 col1\" >0.05299999937415123</td>\n",
       "      <td id=\"T_965b0_row7_col2\" class=\"data row7 col2\" >0.3100000023841858</td>\n",
       "      <td id=\"T_965b0_row7_col3\" class=\"data row7 col3\" >0.9958699941635132</td>\n",
       "      <td id=\"T_965b0_row7_col4\" class=\"data row7 col4\" >7.099999904632568</td>\n",
       "      <td id=\"T_965b0_row7_col5\" class=\"data row7 col5\" >32.0</td>\n",
       "      <td id=\"T_965b0_row7_col6\" class=\"data row7 col6\" >3.309999942779541</td>\n",
       "      <td id=\"T_965b0_row7_col7\" class=\"data row7 col7\" >7.400000095367432</td>\n",
       "      <td id=\"T_965b0_row7_col8\" class=\"data row7 col8\" >0.5899999737739563</td>\n",
       "      <td id=\"T_965b0_row7_col9\" class=\"data row7 col9\" >211.0</td>\n",
       "      <td id=\"T_965b0_row7_col10\" class=\"data row7 col10\" >0.20000000298023224</td>\n",
       "      <td id=\"T_965b0_row7_col11\" class=\"data row7 col11\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_965b0_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_965b0_row8_col0\" class=\"data row8 col0\" >8.600000381469727</td>\n",
       "      <td id=\"T_965b0_row8_col1\" class=\"data row8 col1\" >0.04100000113248825</td>\n",
       "      <td id=\"T_965b0_row8_col2\" class=\"data row8 col2\" >0.6200000047683716</td>\n",
       "      <td id=\"T_965b0_row8_col3\" class=\"data row8 col3\" >0.9976000189781189</td>\n",
       "      <td id=\"T_965b0_row8_col4\" class=\"data row8 col4\" >7.199999809265137</td>\n",
       "      <td id=\"T_965b0_row8_col5\" class=\"data row8 col5\" >70.0</td>\n",
       "      <td id=\"T_965b0_row8_col6\" class=\"data row8 col6\" >3.0799999237060547</td>\n",
       "      <td id=\"T_965b0_row8_col7\" class=\"data row8 col7\" >10.800000190734863</td>\n",
       "      <td id=\"T_965b0_row8_col8\" class=\"data row8 col8\" >0.49000000953674316</td>\n",
       "      <td id=\"T_965b0_row8_col9\" class=\"data row8 col9\" >189.0</td>\n",
       "      <td id=\"T_965b0_row8_col10\" class=\"data row8 col10\" >0.4000000059604645</td>\n",
       "      <td id=\"T_965b0_row8_col11\" class=\"data row8 col11\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_965b0_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_965b0_row9_col0\" class=\"data row9 col0\" >11.899999618530273</td>\n",
       "      <td id=\"T_965b0_row9_col1\" class=\"data row9 col1\" >0.03400000184774399</td>\n",
       "      <td id=\"T_965b0_row9_col2\" class=\"data row9 col2\" >0.36000001430511475</td>\n",
       "      <td id=\"T_965b0_row9_col3\" class=\"data row9 col3\" >0.9908499717712402</td>\n",
       "      <td id=\"T_965b0_row9_col4\" class=\"data row9 col4\" >7.300000190734863</td>\n",
       "      <td id=\"T_965b0_row9_col5\" class=\"data row9 col5\" >30.0</td>\n",
       "      <td id=\"T_965b0_row9_col6\" class=\"data row9 col6\" >3.25</td>\n",
       "      <td id=\"T_965b0_row9_col7\" class=\"data row9 col7\" >2.0999999046325684</td>\n",
       "      <td id=\"T_965b0_row9_col8\" class=\"data row9 col8\" >0.4000000059604645</td>\n",
       "      <td id=\"T_965b0_row9_col9\" class=\"data row9 col9\" >177.0</td>\n",
       "      <td id=\"T_965b0_row9_col10\" class=\"data row9 col10\" >0.25</td>\n",
       "      <td id=\"T_965b0_row9_col11\" class=\"data row9 col11\" >8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "   features/alcohol  features/chlorides  features/citric acid   \n",
       "0               9.0               0.054                  0.34  \\\n",
       "1              12.2               0.063                  0.49   \n",
       "2              11.2               0.029                  0.11   \n",
       "3               9.0               0.110                  0.27   \n",
       "4              12.0               0.035                  0.30   \n",
       "5              10.3               0.055                  0.39   \n",
       "6              10.7               0.054                  0.35   \n",
       "7              10.4               0.053                  0.31   \n",
       "8               8.6               0.041                  0.62   \n",
       "9              11.9               0.034                  0.36   \n",
       "\n",
       "   features/density  features/fixed acidity  features/free sulfur dioxide   \n",
       "0           1.00080                     7.6                          44.0  \\\n",
       "1           0.99110                     6.3                          35.0   \n",
       "2           0.99076                     5.3                           6.0   \n",
       "3           0.99672                     6.6                          20.0   \n",
       "4           0.99016                     5.9                          57.0   \n",
       "5           0.99652                     7.0                          42.0   \n",
       "6           0.99178                     7.3                          31.0   \n",
       "7           0.99587                     7.1                          32.0   \n",
       "8           0.99760                     7.2                          70.0   \n",
       "9           0.99085                     7.3                          30.0   \n",
       "\n",
       "   features/pH  features/residual sugar  features/sulphates   \n",
       "0         3.22                    18.35                0.55  \\\n",
       "1         3.38                     1.20                0.42   \n",
       "2         3.51                     1.10                0.48   \n",
       "3         3.08                    10.70                0.41   \n",
       "4         3.09                     3.80                0.34   \n",
       "5         3.37                     7.50                0.54   \n",
       "6         3.18                     1.60                0.47   \n",
       "7         3.31                     7.40                0.59   \n",
       "8         3.08                    10.80                0.49   \n",
       "9         3.25                     2.10                0.40   \n",
       "\n",
       "   features/total sulfur dioxide  features/volatile acidity  quality  \n",
       "0                          197.0                       0.32        5  \n",
       "1                           92.0                       0.27        6  \n",
       "2                           51.0                       0.43        4  \n",
       "3                          103.0                       0.41        6  \n",
       "4                          135.0                       0.34        6  \n",
       "5                          218.0                       0.31        5  \n",
       "6                          148.0                       0.28        5  \n",
       "7                          211.0                       0.20        6  \n",
       "8                          189.0                       0.40        4  \n",
       "9                          177.0                       0.25        8  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a few examples from the train dataset\n",
    "tfds.as_dataframe(ds_train.take(10), ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance check : is the dataset imbalanced?\n",
    "#fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "#labels, counts = np.unique(np.fromiter(ds_train.map(lambda x, y: y), np.int32), \n",
    "#                       return_counts=True)\n",
    "#ax.set_xlabel('Counts')\n",
    "#ax.set_title(\"Counts by type of terrain\");\n",
    "#sns.barplot(x=counts, y=[class_names[l] for l in labels], label=\"Total\")\n",
    "#ax.grid(True,ls='--')\n",
    "#sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, batch_size=1, shuffle_buffer_size=1000):\n",
    "  ds = ds.map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
    "  ds = ds.prefetch(buffer_size=4898)\n",
    "  ds = ds.cache()\n",
    "  # shuffle the dataset\n",
    "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "  # split to batches\n",
    "  ds = ds.batch(batch_size)\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model is training.\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "# preprocess training & validation sets\n",
    "ds_train = prepare_for_training(ds_train, batch_size=batch_size,shuffle_buffer_size=len(ds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model inputs\n",
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for name in feature_names:\n",
    "        inputs[name] = layers.Input(\n",
    "            name=name, shape=(1,), dtype=tf.float32\n",
    "        )\n",
    "    return inputs\n",
    "\n",
    "# Create Standard Neural Network\n",
    "def base_neural_network(hidden_units=None):\n",
    "    inputs = create_model_inputs()\n",
    "    input_values = [value for _, value in sorted(inputs.items())]\n",
    "    features = keras.layers.concatenate(input_values)\n",
    "    features = layers.BatchNormalization()(features)\n",
    "\n",
    "    # Create hidden layers with deterministic weights using the Dense layer.\n",
    "    for units in hidden_units:\n",
    "        features = layers.Dense(units, activation=\"sigmoid\")(features)\n",
    "    # The output is deterministic: a single point estimate.\n",
    "    outputs = layers.Dense(units=1)(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to train and evaluate a model (experiment run)\n",
    "def run_experiment(model, loss, train_dataset, test_dataset, num_epochs, learning_rate):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    print(\"Model training started ...\")\n",
    "    model.fit(\n",
    "        train_dataset, \n",
    "        epochs=num_epochs, \n",
    "        validation_data=test_dataset)\n",
    "    \n",
    "    print(\"Model training finished.\")\n",
    "    _, rmse = model.evaluate(train_dataset, verbose=0)\n",
    "    print(f\"Train RMSE: {round(rmse, 3)}\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    _, rmse = model.evaluate(test_dataset, verbose=0)\n",
    "    print(f\"Test RMSE: {round(rmse, 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_type = 'nn'\n",
    "model_name = \"wine_quality_classification_\"+arch_type\n",
    "model_path = os.path.join(\"../models\", model_name + \".h5\")\n",
    "if not os.path.exists(\"../models\"):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Training <a name=\"model training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 22:17:55.625866: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-23 22:17:55.626625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3412/3429 [============================>.] - ETA: 0s - loss: 2.2392 - root_mean_squared_error: 1.4964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 22:18:01.958063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-05-23 22:18:01.958642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/backend.py\", line 3581, in concatenate\n        return tf.concat([to_dense(x) for x in tensors], axis)\n\n    ValueError: Exception encountered when calling layer 'concatenate_7' (type Concatenate).\n    \n    Can't concatenate scalars (use tf.stack instead) for '{{node model_7/concatenate_7/concat}} = ConcatV2[N=11, T=DT_FLOAT, Tidx=DT_INT32](IteratorGetNext, IteratorGetNext:1, IteratorGetNext:2, IteratorGetNext:3, IteratorGetNext:4, IteratorGetNext:5, IteratorGetNext:6, IteratorGetNext:7, model_7/Cast, IteratorGetNext:9, IteratorGetNext:10, model_7/concatenate_7/concat/axis)' with input shapes: [], [], [], [], [], [], [], [], [], [], [], [].\n    \n    Call arguments received by layer 'concatenate_7' (type Concatenate):\n      • inputs=['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m      4\u001b[0m nn_model \u001b[39m=\u001b[39m base_neural_network(hidden_units\u001b[39m=\u001b[39mhidden_units)\n\u001b[0;32m----> 5\u001b[0m run_experiment(\n\u001b[1;32m      6\u001b[0m     model\u001b[39m=\u001b[39;49mnn_model, \n\u001b[1;32m      7\u001b[0m     loss\u001b[39m=\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlosses\u001b[39m.\u001b[39;49mMeanSquaredError(), \n\u001b[1;32m      8\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mds_train, \n\u001b[1;32m      9\u001b[0m     test_dataset\u001b[39m=\u001b[39;49mds_test,\n\u001b[1;32m     10\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m     11\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mlearning_rate)\n",
      "Cell \u001b[0;32mIn[77], line 37\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(model, loss, train_dataset, test_dataset, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     30\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     31\u001b[0m     optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mRMSprop(learning_rate\u001b[39m=\u001b[39mlearning_rate),\n\u001b[1;32m     32\u001b[0m     loss\u001b[39m=\u001b[39mloss,\n\u001b[1;32m     33\u001b[0m     metrics\u001b[39m=\u001b[39m[keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mRootMeanSquaredError()],\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStart training the model...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     38\u001b[0m     train_dataset, \n\u001b[1;32m     39\u001b[0m     epochs\u001b[39m=\u001b[39;49mnum_epochs, \n\u001b[1;32m     40\u001b[0m     validation_data\u001b[39m=\u001b[39;49mtest_dataset)\n\u001b[1;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel training finished.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m _, rmse \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(train_dataset, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file1onrir3h.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/codespace/.local/lib/python3.10/site-packages/keras/backend.py\", line 3581, in concatenate\n        return tf.concat([to_dense(x) for x in tensors], axis)\n\n    ValueError: Exception encountered when calling layer 'concatenate_7' (type Concatenate).\n    \n    Can't concatenate scalars (use tf.stack instead) for '{{node model_7/concatenate_7/concat}} = ConcatV2[N=11, T=DT_FLOAT, Tidx=DT_INT32](IteratorGetNext, IteratorGetNext:1, IteratorGetNext:2, IteratorGetNext:3, IteratorGetNext:4, IteratorGetNext:5, IteratorGetNext:6, IteratorGetNext:7, model_7/Cast, IteratorGetNext:9, IteratorGetNext:10, model_7/concatenate_7/concat/axis)' with input shapes: [], [], [], [], [], [], [], [], [], [], [], [].\n    \n    Call arguments received by layer 'concatenate_7' (type Concatenate):\n      • inputs=['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']\n"
     ]
    }
   ],
   "source": [
    "hidden_units = [8, 8]\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "nn_model = base_neural_network(hidden_units=hidden_units)\n",
    "run_experiment(\n",
    "    model=nn_model, \n",
    "    loss=keras.losses.MeanSquaredError(), \n",
    "    train_dataset=ds_train, \n",
    "    test_dataset=ds_test,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
