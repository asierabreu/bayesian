{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The task at hand is classification of wine quality\n",
    "\n",
    "We will use 3 different approaches:\n",
    "\n",
    "- A standard neural network (feed fordward nn)\n",
    "- A bayesian neural network that will take into account epistemic (model) uncertainty on the predicted labels\n",
    "- A probabilistic neural network that will take into account both aleatoric (data) and epistemic (model) uncertainty on the predicted labels\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. [Data Inspection](#inspection) \n",
    "    - Loading\n",
    "    - Inspection\n",
    "    - Preprocessing\n",
    "2. [Modeling](#model-definition)\n",
    "    - Standard Neural Network\n",
    "    - Bayesian Neural Network\n",
    "    - Probabilistic Neural Network\n",
    "3. [Prediction](#prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Software install (as required)\n",
    "#!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 15:25:45.819146: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-24 15:25:47.818817: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-24 15:25:47.819960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 15:25:51.825633: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/codespace/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Inspection <a name=\"inspection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_name=\"wine_quality\",buffer_size=4998,split=\"train\",batch_size=256,train_size=3000):\n",
    "    ds , ds_info = tfds.load(name=dataset_name, as_supervised=True, split=split ,with_info=True)\n",
    "    \n",
    "    (ds.map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
    "        .prefetch(buffer_size=buffer_size)\n",
    "        .cache()\n",
    "    )\n",
    "    # Train : we shuffle with a buffer the same size as the dataset.\n",
    "    ds_train = (\n",
    "        ds\n",
    "        .take(train_size)\n",
    "        .shuffle(buffer_size=train_size)\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "    # Test : no shuffle\n",
    "    ds_test = (\n",
    "        ds\n",
    "        .skip(train_size)\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "\n",
    "    return ds_train, ds_test, ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 4898\n",
    "batch_size = 256\n",
    "train_size = int(dataset_size * 0.85)\n",
    "ds_train,ds_test ,ds_info = load_data(\n",
    "    dataset_name=\"wine_quality\",\n",
    "    buffer_size=dataset_size, # We prefetch with a buffer the same size as the dataset because th dataset is very small and fits into memory.\n",
    "    batch_size=batch_size,\n",
    "    train_size=train_size\n",
    "    ) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 20\n",
      "Train set size: 17\n",
      "Test set size : 3\n",
      "Feature names : ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic Info\n",
    "feature_names=list(ds_info.features['features'].keys())\n",
    "print(\"Total examples: %d\" %(len(ds_train)+len(ds_test)))\n",
    "print(\"Train set size: %d\" %len(ds_train)) \n",
    "print(\"Test set size : %d\" %len(ds_test))   \n",
    "print(\"Feature names : %s\" %feature_names)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 15:48:44.657983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-24 15:48:44.658565: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e513f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e513f_level0_col0\" class=\"col_heading level0 col0\" >features/alcohol</th>\n",
       "      <th id=\"T_e513f_level0_col1\" class=\"col_heading level0 col1\" >features/chlorides</th>\n",
       "      <th id=\"T_e513f_level0_col2\" class=\"col_heading level0 col2\" >features/citric acid</th>\n",
       "      <th id=\"T_e513f_level0_col3\" class=\"col_heading level0 col3\" >features/density</th>\n",
       "      <th id=\"T_e513f_level0_col4\" class=\"col_heading level0 col4\" >features/fixed acidity</th>\n",
       "      <th id=\"T_e513f_level0_col5\" class=\"col_heading level0 col5\" >features/free sulfur dioxide</th>\n",
       "      <th id=\"T_e513f_level0_col6\" class=\"col_heading level0 col6\" >features/pH</th>\n",
       "      <th id=\"T_e513f_level0_col7\" class=\"col_heading level0 col7\" >features/residual sugar</th>\n",
       "      <th id=\"T_e513f_level0_col8\" class=\"col_heading level0 col8\" >features/sulphates</th>\n",
       "      <th id=\"T_e513f_level0_col9\" class=\"col_heading level0 col9\" >features/total sulfur dioxide</th>\n",
       "      <th id=\"T_e513f_level0_col10\" class=\"col_heading level0 col10\" >features/volatile acidity</th>\n",
       "      <th id=\"T_e513f_level0_col11\" class=\"col_heading level0 col11\" >quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e513f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e513f_row0_col0\" class=\"data row0 col0\" >8.899999618530273</td>\n",
       "      <td id=\"T_e513f_row0_col1\" class=\"data row0 col1\" >0.04699999839067459</td>\n",
       "      <td id=\"T_e513f_row0_col2\" class=\"data row0 col2\" >0.20000000298023224</td>\n",
       "      <td id=\"T_e513f_row0_col3\" class=\"data row0 col3\" >0.9976000189781189</td>\n",
       "      <td id=\"T_e513f_row0_col4\" class=\"data row0 col4\" >5.800000190734863</td>\n",
       "      <td id=\"T_e513f_row0_col5\" class=\"data row0 col5\" >26.0</td>\n",
       "      <td id=\"T_e513f_row0_col6\" class=\"data row0 col6\" >3.0899999141693115</td>\n",
       "      <td id=\"T_e513f_row0_col7\" class=\"data row0 col7\" >16.049999237060547</td>\n",
       "      <td id=\"T_e513f_row0_col8\" class=\"data row0 col8\" >0.46000000834465027</td>\n",
       "      <td id=\"T_e513f_row0_col9\" class=\"data row0 col9\" >166.0</td>\n",
       "      <td id=\"T_e513f_row0_col10\" class=\"data row0 col10\" >0.33000001311302185</td>\n",
       "      <td id=\"T_e513f_row0_col11\" class=\"data row0 col11\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e513f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e513f_row1_col0\" class=\"data row1 col0\" >11.0</td>\n",
       "      <td id=\"T_e513f_row1_col1\" class=\"data row1 col1\" >0.050999999046325684</td>\n",
       "      <td id=\"T_e513f_row1_col2\" class=\"data row1 col2\" >0.3499999940395355</td>\n",
       "      <td id=\"T_e513f_row1_col3\" class=\"data row1 col3\" >0.991599977016449</td>\n",
       "      <td id=\"T_e513f_row1_col4\" class=\"data row1 col4\" >6.199999809265137</td>\n",
       "      <td id=\"T_e513f_row1_col5\" class=\"data row1 col5\" >24.0</td>\n",
       "      <td id=\"T_e513f_row1_col6\" class=\"data row1 col6\" >3.369999885559082</td>\n",
       "      <td id=\"T_e513f_row1_col7\" class=\"data row1 col7\" >0.699999988079071</td>\n",
       "      <td id=\"T_e513f_row1_col8\" class=\"data row1 col8\" >0.4300000071525574</td>\n",
       "      <td id=\"T_e513f_row1_col9\" class=\"data row1 col9\" >111.0</td>\n",
       "      <td id=\"T_e513f_row1_col10\" class=\"data row1 col10\" >0.23000000417232513</td>\n",
       "      <td id=\"T_e513f_row1_col11\" class=\"data row1 col11\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e513f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e513f_row2_col0\" class=\"data row2 col0\" >12.399999618530273</td>\n",
       "      <td id=\"T_e513f_row2_col1\" class=\"data row2 col1\" >0.01600000075995922</td>\n",
       "      <td id=\"T_e513f_row2_col2\" class=\"data row2 col2\" >0.41999998688697815</td>\n",
       "      <td id=\"T_e513f_row2_col3\" class=\"data row2 col3\" >0.9900699853897095</td>\n",
       "      <td id=\"T_e513f_row2_col4\" class=\"data row2 col4\" >6.099999904632568</td>\n",
       "      <td id=\"T_e513f_row2_col5\" class=\"data row2 col5\" >31.0</td>\n",
       "      <td id=\"T_e513f_row2_col6\" class=\"data row2 col6\" >3.1500000953674316</td>\n",
       "      <td id=\"T_e513f_row2_col7\" class=\"data row2 col7\" >5.0</td>\n",
       "      <td id=\"T_e513f_row2_col8\" class=\"data row2 col8\" >0.3100000023841858</td>\n",
       "      <td id=\"T_e513f_row2_col9\" class=\"data row2 col9\" >113.0</td>\n",
       "      <td id=\"T_e513f_row2_col10\" class=\"data row2 col10\" >0.3799999952316284</td>\n",
       "      <td id=\"T_e513f_row2_col11\" class=\"data row2 col11\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e513f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e513f_row3_col0\" class=\"data row3 col0\" >9.800000190734863</td>\n",
       "      <td id=\"T_e513f_row3_col1\" class=\"data row3 col1\" >0.04600000008940697</td>\n",
       "      <td id=\"T_e513f_row3_col2\" class=\"data row3 col2\" >0.30000001192092896</td>\n",
       "      <td id=\"T_e513f_row3_col3\" class=\"data row3 col3\" >0.9941999912261963</td>\n",
       "      <td id=\"T_e513f_row3_col4\" class=\"data row3 col4\" >8.699999809265137</td>\n",
       "      <td id=\"T_e513f_row3_col5\" class=\"data row3 col5\" >29.0</td>\n",
       "      <td id=\"T_e513f_row3_col6\" class=\"data row3 col6\" >3.2200000286102295</td>\n",
       "      <td id=\"T_e513f_row3_col7\" class=\"data row3 col7\" >1.600000023841858</td>\n",
       "      <td id=\"T_e513f_row3_col8\" class=\"data row3 col8\" >0.3799999952316284</td>\n",
       "      <td id=\"T_e513f_row3_col9\" class=\"data row3 col9\" >130.0</td>\n",
       "      <td id=\"T_e513f_row3_col10\" class=\"data row3 col10\" >0.15000000596046448</td>\n",
       "      <td id=\"T_e513f_row3_col11\" class=\"data row3 col11\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e513f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e513f_row4_col0\" class=\"data row4 col0\" >9.699999809265137</td>\n",
       "      <td id=\"T_e513f_row4_col1\" class=\"data row4 col1\" >0.06400000303983688</td>\n",
       "      <td id=\"T_e513f_row4_col2\" class=\"data row4 col2\" >0.28999999165534973</td>\n",
       "      <td id=\"T_e513f_row4_col3\" class=\"data row4 col3\" >0.9973700046539307</td>\n",
       "      <td id=\"T_e513f_row4_col4\" class=\"data row4 col4\" >7.099999904632568</td>\n",
       "      <td id=\"T_e513f_row4_col5\" class=\"data row4 col5\" >56.0</td>\n",
       "      <td id=\"T_e513f_row4_col6\" class=\"data row4 col6\" >3.1600000858306885</td>\n",
       "      <td id=\"T_e513f_row4_col7\" class=\"data row4 col7\" >15.5</td>\n",
       "      <td id=\"T_e513f_row4_col8\" class=\"data row4 col8\" >0.4099999964237213</td>\n",
       "      <td id=\"T_e513f_row4_col9\" class=\"data row4 col9\" >115.5</td>\n",
       "      <td id=\"T_e513f_row4_col10\" class=\"data row4 col10\" >0.12999999523162842</td>\n",
       "      <td id=\"T_e513f_row4_col11\" class=\"data row4 col11\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e513f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e513f_row5_col0\" class=\"data row5 col0\" >9.399999618530273</td>\n",
       "      <td id=\"T_e513f_row5_col1\" class=\"data row5 col1\" >0.04800000041723251</td>\n",
       "      <td id=\"T_e513f_row5_col2\" class=\"data row5 col2\" >0.23999999463558197</td>\n",
       "      <td id=\"T_e513f_row5_col3\" class=\"data row5 col3\" >0.9957000017166138</td>\n",
       "      <td id=\"T_e513f_row5_col4\" class=\"data row5 col4\" >7.0</td>\n",
       "      <td id=\"T_e513f_row5_col5\" class=\"data row5 col5\" >31.0</td>\n",
       "      <td id=\"T_e513f_row5_col6\" class=\"data row5 col6\" >3.2300000190734863</td>\n",
       "      <td id=\"T_e513f_row5_col7\" class=\"data row5 col7\" >6.199999809265137</td>\n",
       "      <td id=\"T_e513f_row5_col8\" class=\"data row5 col8\" >0.6200000047683716</td>\n",
       "      <td id=\"T_e513f_row5_col9\" class=\"data row5 col9\" >228.0</td>\n",
       "      <td id=\"T_e513f_row5_col10\" class=\"data row5 col10\" >0.3199999928474426</td>\n",
       "      <td id=\"T_e513f_row5_col11\" class=\"data row5 col11\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e513f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e513f_row6_col0\" class=\"data row6 col0\" >11.75</td>\n",
       "      <td id=\"T_e513f_row6_col1\" class=\"data row6 col1\" >0.03099999949336052</td>\n",
       "      <td id=\"T_e513f_row6_col2\" class=\"data row6 col2\" >0.25</td>\n",
       "      <td id=\"T_e513f_row6_col3\" class=\"data row6 col3\" >0.9907199740409851</td>\n",
       "      <td id=\"T_e513f_row6_col4\" class=\"data row6 col4\" >5.300000190734863</td>\n",
       "      <td id=\"T_e513f_row6_col5\" class=\"data row6 col5\" >45.0</td>\n",
       "      <td id=\"T_e513f_row6_col6\" class=\"data row6 col6\" >3.309999942779541</td>\n",
       "      <td id=\"T_e513f_row6_col7\" class=\"data row6 col7\" >3.9000000953674316</td>\n",
       "      <td id=\"T_e513f_row6_col8\" class=\"data row6 col8\" >0.5799999833106995</td>\n",
       "      <td id=\"T_e513f_row6_col9\" class=\"data row6 col9\" >130.0</td>\n",
       "      <td id=\"T_e513f_row6_col10\" class=\"data row6 col10\" >0.4000000059604645</td>\n",
       "      <td id=\"T_e513f_row6_col11\" class=\"data row6 col11\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e513f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e513f_row7_col0\" class=\"data row7 col0\" >9.800000190734863</td>\n",
       "      <td id=\"T_e513f_row7_col1\" class=\"data row7 col1\" >0.05400000140070915</td>\n",
       "      <td id=\"T_e513f_row7_col2\" class=\"data row7 col2\" >0.3700000047683716</td>\n",
       "      <td id=\"T_e513f_row7_col3\" class=\"data row7 col3\" >0.99795001745224</td>\n",
       "      <td id=\"T_e513f_row7_col4\" class=\"data row7 col4\" >8.0</td>\n",
       "      <td id=\"T_e513f_row7_col5\" class=\"data row7 col5\" >23.0</td>\n",
       "      <td id=\"T_e513f_row7_col6\" class=\"data row7 col6\" >3.319999933242798</td>\n",
       "      <td id=\"T_e513f_row7_col7\" class=\"data row7 col7\" >9.600000381469727</td>\n",
       "      <td id=\"T_e513f_row7_col8\" class=\"data row7 col8\" >0.4699999988079071</td>\n",
       "      <td id=\"T_e513f_row7_col9\" class=\"data row7 col9\" >159.0</td>\n",
       "      <td id=\"T_e513f_row7_col10\" class=\"data row7 col10\" >0.23000000417232513</td>\n",
       "      <td id=\"T_e513f_row7_col11\" class=\"data row7 col11\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e513f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e513f_row8_col0\" class=\"data row8 col0\" >8.899999618530273</td>\n",
       "      <td id=\"T_e513f_row8_col1\" class=\"data row8 col1\" >0.06599999964237213</td>\n",
       "      <td id=\"T_e513f_row8_col2\" class=\"data row8 col2\" >0.41999998688697815</td>\n",
       "      <td id=\"T_e513f_row8_col3\" class=\"data row8 col3\" >0.9979000091552734</td>\n",
       "      <td id=\"T_e513f_row8_col4\" class=\"data row8 col4\" >7.400000095367432</td>\n",
       "      <td id=\"T_e513f_row8_col5\" class=\"data row8 col5\" >48.0</td>\n",
       "      <td id=\"T_e513f_row8_col6\" class=\"data row8 col6\" >2.890000104904175</td>\n",
       "      <td id=\"T_e513f_row8_col7\" class=\"data row8 col7\" >14.0</td>\n",
       "      <td id=\"T_e513f_row8_col8\" class=\"data row8 col8\" >0.41999998688697815</td>\n",
       "      <td id=\"T_e513f_row8_col9\" class=\"data row8 col9\" >198.0</td>\n",
       "      <td id=\"T_e513f_row8_col10\" class=\"data row8 col10\" >0.23999999463558197</td>\n",
       "      <td id=\"T_e513f_row8_col11\" class=\"data row8 col11\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e513f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e513f_row9_col0\" class=\"data row9 col0\" >11.800000190734863</td>\n",
       "      <td id=\"T_e513f_row9_col1\" class=\"data row9 col1\" >0.032999999821186066</td>\n",
       "      <td id=\"T_e513f_row9_col2\" class=\"data row9 col2\" >0.30000001192092896</td>\n",
       "      <td id=\"T_e513f_row9_col3\" class=\"data row9 col3\" >0.9905999898910522</td>\n",
       "      <td id=\"T_e513f_row9_col4\" class=\"data row9 col4\" >6.300000190734863</td>\n",
       "      <td id=\"T_e513f_row9_col5\" class=\"data row9 col5\" >16.0</td>\n",
       "      <td id=\"T_e513f_row9_col6\" class=\"data row9 col6\" >3.2799999713897705</td>\n",
       "      <td id=\"T_e513f_row9_col7\" class=\"data row9 col7\" >1.7999999523162842</td>\n",
       "      <td id=\"T_e513f_row9_col8\" class=\"data row9 col8\" >0.4000000059604645</td>\n",
       "      <td id=\"T_e513f_row9_col9\" class=\"data row9 col9\" >91.0</td>\n",
       "      <td id=\"T_e513f_row9_col10\" class=\"data row9 col10\" >0.23000000417232513</td>\n",
       "      <td id=\"T_e513f_row9_col11\" class=\"data row9 col11\" >6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "   features/alcohol  features/chlorides  features/citric acid   \n",
       "0              8.90               0.047                  0.20  \\\n",
       "1             11.00               0.051                  0.35   \n",
       "2             12.40               0.016                  0.42   \n",
       "3              9.80               0.046                  0.30   \n",
       "4              9.70               0.064                  0.29   \n",
       "5              9.40               0.048                  0.24   \n",
       "6             11.75               0.031                  0.25   \n",
       "7              9.80               0.054                  0.37   \n",
       "8              8.90               0.066                  0.42   \n",
       "9             11.80               0.033                  0.30   \n",
       "\n",
       "   features/density  features/fixed acidity  features/free sulfur dioxide   \n",
       "0           0.99760                     5.8                          26.0  \\\n",
       "1           0.99160                     6.2                          24.0   \n",
       "2           0.99007                     6.1                          31.0   \n",
       "3           0.99420                     8.7                          29.0   \n",
       "4           0.99737                     7.1                          56.0   \n",
       "5           0.99570                     7.0                          31.0   \n",
       "6           0.99072                     5.3                          45.0   \n",
       "7           0.99795                     8.0                          23.0   \n",
       "8           0.99790                     7.4                          48.0   \n",
       "9           0.99060                     6.3                          16.0   \n",
       "\n",
       "   features/pH  features/residual sugar  features/sulphates   \n",
       "0         3.09                16.049999                0.46  \\\n",
       "1         3.37                 0.700000                0.43   \n",
       "2         3.15                 5.000000                0.31   \n",
       "3         3.22                 1.600000                0.38   \n",
       "4         3.16                15.500000                0.41   \n",
       "5         3.23                 6.200000                0.62   \n",
       "6         3.31                 3.900000                0.58   \n",
       "7         3.32                 9.600000                0.47   \n",
       "8         2.89                14.000000                0.42   \n",
       "9         3.28                 1.800000                0.40   \n",
       "\n",
       "   features/total sulfur dioxide  features/volatile acidity  quality  \n",
       "0                          166.0                       0.33        5  \n",
       "1                          111.0                       0.23        3  \n",
       "2                          113.0                       0.38        7  \n",
       "3                          130.0                       0.15        6  \n",
       "4                          115.5                       0.13        7  \n",
       "5                          228.0                       0.32        6  \n",
       "6                          130.0                       0.40        7  \n",
       "7                          159.0                       0.23        4  \n",
       "8                          198.0                       0.24        6  \n",
       "9                           91.0                       0.23        6  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a few examples from the train dataset\n",
    "tfds.as_dataframe(ds_train.unbatch().take(10), ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance check : is the dataset imbalanced?\n",
    "#fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "#labels, counts = np.unique(np.fromiter(ds_train.unbatch().map(lambda x, y: y), np.int32),  return_counts=True)\n",
    "#ax.set_xlabel('Counts')\n",
    "#ax.set_title(\"Counts by type\");\n",
    "#sns.barplot(x=counts, y=[class_names[l] for l in labels], label=\"Total\")\n",
    "#ax.grid(True,ls='--')\n",
    "#sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, batch_size=1, shuffle_buffer_size=1000):\n",
    "  ds = ds.map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
    "  ds = ds.prefetch(buffer_size=4898)\n",
    "  ds = ds.cache()\n",
    "  # shuffle the dataset\n",
    "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "  # split to batches\n",
    "  ds = ds.batch(batch_size)\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model is training.\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "# preprocess training & validation sets\n",
    "ds_train = prepare_for_training(ds_train, batch_size=batch_size,shuffle_buffer_size=len(ds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model inputs\n",
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for name in feature_names:\n",
    "        inputs[name] = layers.Input(\n",
    "            name=name.replace(\" \",\"_\"), shape=(1,), dtype=tf.float32\n",
    "        )\n",
    "    return inputs\n",
    "\n",
    "# Create Standard Neural Network\n",
    "def base_neural_network(hidden_units=None):\n",
    "    inputs = create_model_inputs()\n",
    "    input_values = [value for _, value in sorted(inputs.items())]\n",
    "    features = keras.layers.concatenate(input_values)\n",
    "    features = layers.BatchNormalization()(features)\n",
    "\n",
    "    # Create hidden layers with deterministic weights using the Dense layer.\n",
    "    for units in hidden_units:\n",
    "        features = layers.Dense(units, activation=\"sigmoid\")(features)\n",
    "    # The output is deterministic: a single point estimate.\n",
    "    outputs = layers.Dense(units=1)(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to train and evaluate a model (experiment run)\n",
    "def run_experiment(model, loss, train_dataset, test_dataset, num_epochs, learning_rate,save=True,model_filename=\"\"):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    print(\"Model training started ...\")\n",
    "    model.fit(\n",
    "        train_dataset, \n",
    "        epochs=num_epochs, \n",
    "        validation_data=test_dataset)\n",
    "    \n",
    "    print(\"Model training finished.\")\n",
    "    _, rmse = model.evaluate(train_dataset, verbose=0)\n",
    "    print(f\"Train RMSE: {round(rmse, 3)}\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    _, rmse = model.evaluate(test_dataset, verbose=0)\n",
    "    print(f\"Test RMSE: {round(rmse, 3)}\")\n",
    "\n",
    "    # save model as required\n",
    "    if save:\n",
    "        print('saving model : %s' %model_filename)\n",
    "        model.save(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_type = 'nn'\n",
    "model_filename = \"wine_quality_classification_\"+arch_type\n",
    "model_path = os.path.join(\"../models\", model_filename + \".h5\")\n",
    "if not os.path.exists(\"../models\"):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Training <a name=\"model training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training started ...\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 9ms/step - loss: 38.3675 - root_mean_squared_error: 6.1942 - val_loss: 33.9572 - val_root_mean_squared_error: 5.8273\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.8448 - root_mean_squared_error: 5.9871 - val_loss: 32.4479 - val_root_mean_squared_error: 5.6963\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.7326 - root_mean_squared_error: 5.8080 - val_loss: 30.6022 - val_root_mean_squared_error: 5.5319\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.7324 - root_mean_squared_error: 5.6332 - val_loss: 28.6952 - val_root_mean_squared_error: 5.3568\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.8150 - root_mean_squared_error: 5.4603 - val_loss: 26.8533 - val_root_mean_squared_error: 5.1820\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.9766 - root_mean_squared_error: 5.2893 - val_loss: 25.1188 - val_root_mean_squared_error: 5.0119\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.2206 - root_mean_squared_error: 5.1206 - val_loss: 23.5062 - val_root_mean_squared_error: 4.8483\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.5473 - root_mean_squared_error: 4.9545 - val_loss: 22.0038 - val_root_mean_squared_error: 4.6908\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.9499 - root_mean_squared_error: 4.7906 - val_loss: 20.6008 - val_root_mean_squared_error: 4.5388\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.4317 - root_mean_squared_error: 4.6294 - val_loss: 19.2861 - val_root_mean_squared_error: 4.3916\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.9960 - root_mean_squared_error: 4.4717 - val_loss: 18.0531 - val_root_mean_squared_error: 4.2489\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 18.6373 - root_mean_squared_error: 4.3171 - val_loss: 16.8879 - val_root_mean_squared_error: 4.1095\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.3564 - root_mean_squared_error: 4.1661 - val_loss: 15.7975 - val_root_mean_squared_error: 3.9746\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1600 - root_mean_squared_error: 4.0199 - val_loss: 14.7735 - val_root_mean_squared_error: 3.8436\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 15.0408 - root_mean_squared_error: 3.8782 - val_loss: 13.8005 - val_root_mean_squared_error: 3.7149\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.9897 - root_mean_squared_error: 3.7403 - val_loss: 12.8854 - val_root_mean_squared_error: 3.5896\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0080 - root_mean_squared_error: 3.6067 - val_loss: 12.0180 - val_root_mean_squared_error: 3.4667\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0863 - root_mean_squared_error: 3.4765 - val_loss: 11.1978 - val_root_mean_squared_error: 3.3463\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2294 - root_mean_squared_error: 3.3510 - val_loss: 10.4281 - val_root_mean_squared_error: 3.2293\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4310 - root_mean_squared_error: 3.2297 - val_loss: 9.7076 - val_root_mean_squared_error: 3.1157\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.6860 - root_mean_squared_error: 3.1122 - val_loss: 9.0261 - val_root_mean_squared_error: 3.0043\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 8.9914 - root_mean_squared_error: 2.9986 - val_loss: 8.3911 - val_root_mean_squared_error: 2.8967\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.3461 - root_mean_squared_error: 2.8890 - val_loss: 7.7922 - val_root_mean_squared_error: 2.7915\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.7422 - root_mean_squared_error: 2.7825 - val_loss: 7.2304 - val_root_mean_squared_error: 2.6889\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.1776 - root_mean_squared_error: 2.6791 - val_loss: 6.7039 - val_root_mean_squared_error: 2.5892\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.6488 - root_mean_squared_error: 2.5785 - val_loss: 6.2076 - val_root_mean_squared_error: 2.4915\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.1514 - root_mean_squared_error: 2.4802 - val_loss: 5.7375 - val_root_mean_squared_error: 2.3953\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.6839 - root_mean_squared_error: 2.3841 - val_loss: 5.2976 - val_root_mean_squared_error: 2.3017\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.2467 - root_mean_squared_error: 2.2906 - val_loss: 4.8841 - val_root_mean_squared_error: 2.2100\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.8344 - root_mean_squared_error: 2.1987 - val_loss: 4.4932 - val_root_mean_squared_error: 2.1197\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.4469 - root_mean_squared_error: 2.1088 - val_loss: 4.1289 - val_root_mean_squared_error: 2.0320\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.0843 - root_mean_squared_error: 2.0210 - val_loss: 3.7846 - val_root_mean_squared_error: 1.9454\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.7438 - root_mean_squared_error: 1.9349 - val_loss: 3.4638 - val_root_mean_squared_error: 1.8611\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.4243 - root_mean_squared_error: 1.8505 - val_loss: 3.1602 - val_root_mean_squared_error: 1.7777\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.1230 - root_mean_squared_error: 1.7672 - val_loss: 2.8779 - val_root_mean_squared_error: 1.6964\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.8421 - root_mean_squared_error: 1.6859 - val_loss: 2.6146 - val_root_mean_squared_error: 1.6170\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.5804 - root_mean_squared_error: 1.6064 - val_loss: 2.3696 - val_root_mean_squared_error: 1.5394\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.3357 - root_mean_squared_error: 1.5283 - val_loss: 2.1395 - val_root_mean_squared_error: 1.4627\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.1069 - root_mean_squared_error: 1.4515 - val_loss: 1.9290 - val_root_mean_squared_error: 1.3889\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.8976 - root_mean_squared_error: 1.3776 - val_loss: 1.7369 - val_root_mean_squared_error: 1.3179\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.7054 - root_mean_squared_error: 1.3059 - val_loss: 1.5603 - val_root_mean_squared_error: 1.2491\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.5292 - root_mean_squared_error: 1.2366 - val_loss: 1.3998 - val_root_mean_squared_error: 1.1831\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3703 - root_mean_squared_error: 1.1706 - val_loss: 1.2601 - val_root_mean_squared_error: 1.1225\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2308 - root_mean_squared_error: 1.1094 - val_loss: 1.1367 - val_root_mean_squared_error: 1.0662\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1086 - root_mean_squared_error: 1.0529 - val_loss: 1.0332 - val_root_mean_squared_error: 1.0165\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0069 - root_mean_squared_error: 1.0035 - val_loss: 0.9471 - val_root_mean_squared_error: 0.9732\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9233 - root_mean_squared_error: 0.9609 - val_loss: 0.8836 - val_root_mean_squared_error: 0.9400\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8607 - root_mean_squared_error: 0.9277 - val_loss: 0.8362 - val_root_mean_squared_error: 0.9145\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8163 - root_mean_squared_error: 0.9035 - val_loss: 0.8100 - val_root_mean_squared_error: 0.9000\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7915 - root_mean_squared_error: 0.8897 - val_loss: 0.7986 - val_root_mean_squared_error: 0.8936\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7804 - root_mean_squared_error: 0.8834 - val_loss: 0.7958 - val_root_mean_squared_error: 0.8921\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7769 - root_mean_squared_error: 0.8814 - val_loss: 0.7958 - val_root_mean_squared_error: 0.8921\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7750 - root_mean_squared_error: 0.8803 - val_loss: 0.7939 - val_root_mean_squared_error: 0.8910\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7734 - root_mean_squared_error: 0.8794 - val_loss: 0.7900 - val_root_mean_squared_error: 0.8888\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7709 - root_mean_squared_error: 0.8780 - val_loss: 0.7888 - val_root_mean_squared_error: 0.8881\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7682 - root_mean_squared_error: 0.8765 - val_loss: 0.7832 - val_root_mean_squared_error: 0.8850\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.7641 - root_mean_squared_error: 0.8741 - val_loss: 0.7769 - val_root_mean_squared_error: 0.8814\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7597 - root_mean_squared_error: 0.8716 - val_loss: 0.7718 - val_root_mean_squared_error: 0.8785\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7542 - root_mean_squared_error: 0.8684 - val_loss: 0.7642 - val_root_mean_squared_error: 0.8742\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7477 - root_mean_squared_error: 0.8647 - val_loss: 0.7574 - val_root_mean_squared_error: 0.8703\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7393 - root_mean_squared_error: 0.8598 - val_loss: 0.7474 - val_root_mean_squared_error: 0.8645\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7308 - root_mean_squared_error: 0.8549 - val_loss: 0.7369 - val_root_mean_squared_error: 0.8585\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7211 - root_mean_squared_error: 0.8492 - val_loss: 0.7264 - val_root_mean_squared_error: 0.8523\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7099 - root_mean_squared_error: 0.8425 - val_loss: 0.7147 - val_root_mean_squared_error: 0.8454\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6997 - root_mean_squared_error: 0.8365 - val_loss: 0.7039 - val_root_mean_squared_error: 0.8390\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6886 - root_mean_squared_error: 0.8298 - val_loss: 0.6910 - val_root_mean_squared_error: 0.8312\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6775 - root_mean_squared_error: 0.8231 - val_loss: 0.6806 - val_root_mean_squared_error: 0.8250\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6676 - root_mean_squared_error: 0.8170 - val_loss: 0.6709 - val_root_mean_squared_error: 0.8191\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6582 - root_mean_squared_error: 0.8113 - val_loss: 0.6627 - val_root_mean_squared_error: 0.8141\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.6512 - root_mean_squared_error: 0.8069 - val_loss: 0.6549 - val_root_mean_squared_error: 0.8093\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6432 - root_mean_squared_error: 0.8020 - val_loss: 0.6484 - val_root_mean_squared_error: 0.8052\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6361 - root_mean_squared_error: 0.7976 - val_loss: 0.6419 - val_root_mean_squared_error: 0.8012\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6284 - root_mean_squared_error: 0.7927 - val_loss: 0.6354 - val_root_mean_squared_error: 0.7971\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6235 - root_mean_squared_error: 0.7896 - val_loss: 0.6290 - val_root_mean_squared_error: 0.7931\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6177 - root_mean_squared_error: 0.7860 - val_loss: 0.6248 - val_root_mean_squared_error: 0.7904\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6125 - root_mean_squared_error: 0.7826 - val_loss: 0.6199 - val_root_mean_squared_error: 0.7873\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6068 - root_mean_squared_error: 0.7790 - val_loss: 0.6156 - val_root_mean_squared_error: 0.7846\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6037 - root_mean_squared_error: 0.7770 - val_loss: 0.6115 - val_root_mean_squared_error: 0.7820\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6017 - root_mean_squared_error: 0.7757 - val_loss: 0.6073 - val_root_mean_squared_error: 0.7793\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5982 - root_mean_squared_error: 0.7735 - val_loss: 0.6036 - val_root_mean_squared_error: 0.7769\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5959 - root_mean_squared_error: 0.7719 - val_loss: 0.6004 - val_root_mean_squared_error: 0.7749\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5929 - root_mean_squared_error: 0.7700 - val_loss: 0.5976 - val_root_mean_squared_error: 0.7730\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5898 - root_mean_squared_error: 0.7680 - val_loss: 0.5957 - val_root_mean_squared_error: 0.7718\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5891 - root_mean_squared_error: 0.7676 - val_loss: 0.5918 - val_root_mean_squared_error: 0.7693\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5862 - root_mean_squared_error: 0.7656 - val_loss: 0.5898 - val_root_mean_squared_error: 0.7680\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5839 - root_mean_squared_error: 0.7642 - val_loss: 0.5869 - val_root_mean_squared_error: 0.7661\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5818 - root_mean_squared_error: 0.7628 - val_loss: 0.5846 - val_root_mean_squared_error: 0.7646\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5800 - root_mean_squared_error: 0.7616 - val_loss: 0.5826 - val_root_mean_squared_error: 0.7633\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5781 - root_mean_squared_error: 0.7603 - val_loss: 0.5805 - val_root_mean_squared_error: 0.7619\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5784 - root_mean_squared_error: 0.7605 - val_loss: 0.5788 - val_root_mean_squared_error: 0.7608\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5744 - root_mean_squared_error: 0.7579 - val_loss: 0.5772 - val_root_mean_squared_error: 0.7597\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5743 - root_mean_squared_error: 0.7578 - val_loss: 0.5761 - val_root_mean_squared_error: 0.7590\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5724 - root_mean_squared_error: 0.7566 - val_loss: 0.5741 - val_root_mean_squared_error: 0.7577\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5741 - root_mean_squared_error: 0.7577 - val_loss: 0.5731 - val_root_mean_squared_error: 0.7570\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5717 - root_mean_squared_error: 0.7561 - val_loss: 0.5715 - val_root_mean_squared_error: 0.7560\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5702 - root_mean_squared_error: 0.7551 - val_loss: 0.5702 - val_root_mean_squared_error: 0.7551\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5706 - root_mean_squared_error: 0.7554 - val_loss: 0.5693 - val_root_mean_squared_error: 0.7545\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5680 - root_mean_squared_error: 0.7537 - val_loss: 0.5686 - val_root_mean_squared_error: 0.7541\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5681 - root_mean_squared_error: 0.7537 - val_loss: 0.5677 - val_root_mean_squared_error: 0.7534\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5677 - root_mean_squared_error: 0.7535 - val_loss: 0.5670 - val_root_mean_squared_error: 0.7530\n",
      "Model training finished.\n",
      "Train RMSE: 0.752\n",
      "Evaluating model performance...\n",
      "Test RMSE: 0.753\n",
      "saving model : wine_quality_classification_nn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) pH with unsupported characters which will be renamed to ph in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: wine_quality_classification_nn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: wine_quality_classification_nn/assets\n"
     ]
    }
   ],
   "source": [
    "hidden_units = [8, 8]\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "nn_model = base_neural_network(hidden_units=hidden_units)\n",
    "run_experiment(\n",
    "    model=nn_model, \n",
    "    loss=keras.losses.MeanSquaredError(), \n",
    "    train_dataset=ds_train, \n",
    "    test_dataset=ds_test,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    model_filename=model_filename)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a sample from the test set use the model to obtain predictions for them. Note that since the baseline model is deterministic, we get a single a point estimate prediction for each test example, with no information about the uncertainty of the model nor the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 15:59:25.811594: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-24 15:59:25.812405: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'alcohol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      2\u001b[0m examples, targets \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ds_test\u001b[39m.\u001b[39munbatch()\u001b[39m.\u001b[39mshuffle(batch_size \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mbatch(sample))[\n\u001b[1;32m      3\u001b[0m     \u001b[39m0\u001b[39m\n\u001b[1;32m      4\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m predicted \u001b[39m=\u001b[39m base_neural_network(examples)\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(sample):\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicted: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(\u001b[39mfloat\u001b[39m(predicted[idx][\u001b[39m0\u001b[39m]),\u001b[39m \u001b[39m\u001b[39m1\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m - Actual: \u001b[39m\u001b[39m{\u001b[39;00mtargets[idx]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 19\u001b[0m, in \u001b[0;36mbase_neural_network\u001b[0;34m(hidden_units)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# Create hidden layers with deterministic weights using the Dense layer.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m units \u001b[39min\u001b[39;00m hidden_units:\n\u001b[0;32m---> 19\u001b[0m     features \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mDense(units, activation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msigmoid\u001b[39;49m\u001b[39m\"\u001b[39;49m)(features)\n\u001b[1;32m     20\u001b[0m \u001b[39m# The output is deterministic: a single point estimate.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m outputs \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDense(units\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)(features)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/dtensor/utils.py:96\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[0;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[39mif\u001b[39;00m layout:\n\u001b[1;32m     94\u001b[0m             layout_args[variable_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_layout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m layout\n\u001b[0;32m---> 96\u001b[0m init_method(layer_instance, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     98\u001b[0m \u001b[39m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m layout_param_name, layout \u001b[39min\u001b[39;00m layout_args\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/layers/core/dense.py:119\u001b[0m, in \u001b[0;36mDense.__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@utils\u001b[39m\u001b[39m.\u001b[39mallow_initializer_layout\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    116\u001b[0m ):\n\u001b[1;32m    117\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(activity_regularizer\u001b[39m=\u001b[39mactivity_regularizer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(units) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(units, \u001b[39mint\u001b[39m) \u001b[39melse\u001b[39;00m units\n\u001b[1;32m    120\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    121\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReceived an invalid value for `units`, expected \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ma positive integer. Received: units=\u001b[39m\u001b[39m{\u001b[39;00munits\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'alcohol'"
     ]
    }
   ],
   "source": [
    "sample = 10\n",
    "examples, targets = list(ds_test.unbatch().shuffle(batch_size * 10).batch(sample))[\n",
    "    0\n",
    "]\n",
    "\n",
    "predicted = base_neural_network(examples).numpy()\n",
    "for idx in range(sample):\n",
    "    print(f\"Predicted: {round(float(predicted[idx][0]), 1)} - Actual: {targets[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
